{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YESICA287/Datos-Masivos-Equipo/blob/main/RedNeuronalJY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UF-imjZMYvD",
        "outputId": "3ec383f8-14bf-46ed-9ea4-2e9752e2841c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "XWMH6y4ZNZa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jade**"
      ],
      "metadata": {
        "id": "py7f2ic_UaOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cap = cv2.VideoCapture('')\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Jade.MOV')"
      ],
      "metadata": {
        "id": "49eL3BuiNc-h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = 15\n",
        "i = 0\n",
        "b = 'Jade'\n",
        "\n",
        "while i < 1001:\n",
        "    ret, frame = cap.read()\n",
        "    i += 1\n",
        "\n",
        "    if not ret:  # Si no se lee correctamente el fotograma, sal del bucle\n",
        "        break\n",
        "\n",
        "    if i <= 750:\n",
        "        # Guardar cada fotograma en el disco usando el método imwrite\n",
        "        writeTo = '/content/drive/MyDrive/Imagenes/Train/Jade' + '/' + str(i) + '_F' + str(b) + '.jpg'\n",
        "        width = int(frame.shape[1] * 30 / 100)\n",
        "        height = int (frame.shape[0] * 26 / 100)\n",
        "        dim = (width, height)\n",
        "        #resize image\n",
        "        resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "        cv2.imwrite(writeTo, resized)\n",
        "    else:\n",
        "        # Guardar cada fotograma en el disco usando el método imwrite\n",
        "        writeTo = '/content/drive/MyDrive/Imagenes/Test/Jade' + '/' + str(i) + '_F' + str(b) + '.jpg'\n",
        "        width = int(frame.shape[1] * 30 / 100)\n",
        "        height = int (frame.shape[0] * 26 / 100)\n",
        "        dim = (width, height)\n",
        "        cv2.imwrite(writeTo, resized)\n",
        "\n",
        "        cap.release()\n"
      ],
      "metadata": {
        "id": "Y39zYLZNPQrc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yesica**"
      ],
      "metadata": {
        "id": "ashe3wZWUft8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cap = cv2.VideoCapture('')\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Yess.MOV')"
      ],
      "metadata": {
        "id": "KmCb4hTVUY6A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames=15\n",
        "i = 0\n",
        "b='Yesica'\n",
        "while(i < 1001):\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  if not ret:  # Si no se lee correctamente el fotograma, sal del bucle\n",
        "        break\n",
        "\n",
        "  #print (frame)\n",
        "  i += 1\n",
        "  if i <= 750:\n",
        "    #save Frame by Frame into disk using imwrite method\n",
        "    writeTo = '/content/drive/MyDrive/Imagenes/Train/Yesica' + '/'+ str(i) + '_F'+str(b)+'.jpg'\n",
        "    #print(writeTo)\n",
        "    width = int(frame.shape[1] * 30 / 100)\n",
        "    height = int (frame.shape[0] * 26 / 100)\n",
        "    dim = (width, height)\n",
        "\n",
        "    #resize image\n",
        "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    cv2.imwrite(writeTo, resized)\n",
        "\n",
        "  else:\n",
        "    #save Frame by Frame into disk using imwrite method\n",
        "    writeTo = '/content/drive/MyDrive/Imagenes/Test/Yesica' + '/'+ str(i) + '_F'+str(b)+'.jpg'\n",
        "    #print(writeTo)\n",
        "    width = int(frame.shape[1] * 30 / 100)\n",
        "    height = int (frame.shape[0] * 26 / 100)\n",
        "    dim = (width, height)\n",
        "    cv2.imwrite(writeTo, resized)\n",
        "\n",
        "    cap.release()\n"
      ],
      "metadata": {
        "id": "eraBJDaIUk2E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = '/content/drive/MyDrive/Imagenes/Train/Jade' # Datos de entrenamiento\n",
        "test_dir = '/content/drive/MyDrive/Imagenes/Test/Jade'  #Datos de Prueba"
      ],
      "metadata": {
        "id": "rsRGJukb3lJi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 750 # Inicialmente 64\n",
        "img_height = 512\n",
        "img_width = 512"
      ],
      "metadata": {
        "id": "6Fsmw_gc3dOh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir, #ruta de la carpeta con imágenes\n",
        "    validation_split=0.3, #70% para el conjunto de entrenamiento y 30% para el conjunto de prueba\n",
        "    subset='training', # categoría entrenamiento\n",
        "    seed=123, # Semilla aleatoria opcional\n",
        "    image_size=(img_height, img_width), #Tamaño de las imágenes\n",
        "    batch_size=batch_size) #Tamaño de lote de datos, si no se específica entonces de determina 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "KVRI6We934b-",
        "outputId": "50ccf9a8-2b9d-4e7f-c411-82ccbb09308d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 0 classes.\n",
            "Using 0 files for training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5c7457772fd1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#ruta de la carpeta con imágenes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#70% para el conjunto de entrenamiento y 30% para el conjunto de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# categoría entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Semilla aleatoria opcional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found in directory /content/drive/MyDrive/Imagenes/Train/Jade. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir, #ruta de la carpeta con imágenes\n",
        "  validation_split=0.3, #70% para el conjunto de entrenamiento y 30% para el conjunto de prueba\n",
        "  subset=\"validation\", # categoría validación (prueba)\n",
        "  seed=123, #Semilla aleatoria opcional\n",
        "  image_size=(img_height, img_width), #Tamaño de las imágenes\n",
        "  batch_size=batch_size) #Tamaño de lote de datos, si no se específica entonces de determina 32"
      ],
      "metadata": {
        "id": "j2VjWNeu3_yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "uh8k3qfG4CeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (10,10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype('uint8'))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "rbf3v1SJ4E2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 3)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Jz7nH3DO4IPH",
        "outputId": "92d83228-14e0-4c9c-c3dd-2f69db953cbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6975b4fe05e4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(512, 512, 3)),\n",
        "  tf.keras.layers.MaxPool2D((2,2)),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPool2D((2,2)),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPool2D((2,2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(units=3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(optimizer='adam', loss = 'CategoricalCrossentropy',\n",
        "                   metrics = ['accuracy']) #0.001-> Default, batch_size -> Default 32\n",
        ""
      ],
      "metadata": {
        "id": "bUf2xoPh4N3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " history = model.fit(\n",
        "    X_train, y_train, # Datos de entrenamiento\n",
        "    epochs = 30, #Número de epocas\n",
        "    validation_data=(X_test, y_test), #Se asigan los datos de validación\n",
        "    verbose=1 #verbosidad. 0 = sin impresión, 1 = barra de progreso, 2 = una línea por época.\n",
        ")"
      ],
      "metadata": {
        "id": "Bomqf1J64Q2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(X_train,y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test,y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "-9ZZSn1G4Tfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "metadata": {
        "id": "p6dPQj9_4VYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}